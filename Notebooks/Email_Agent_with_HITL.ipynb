{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "overview",
      "metadata": {
        "id": "overview"
      },
      "source": [
        "# Human-in-the-Loop (HITL) Email Agent using LangGraph and Qubrid AI\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/QubridAI-Inc/qubrid-cookbook/blob/main/Notebooks/Email_Agent_with_HITL.ipynb)\n",
        "\n",
        "![Qubrid x Langgraph](../../qubrid-cookbook/Assets/Images/Langgraph_x_Qubrid.png)\n",
        "\n",
        "This notebook shows how to build a Human-in-the-Loop (HITL) email assistant using LangGraph and Qubrid AI. The agent can draft and refine emails, but the final send action is strictly gated by explicit human approval.\n",
        "\n",
        "- **GPT-OSS-120B** on the Qubrid AI Platform for high-quality reasoning, email drafting, and feedback handling\n",
        "\n",
        "- **LangGraph Interrupt & Resume** patterns to enforce a mandatory human approval checkpoint\n",
        "\n",
        "- **Hybrid state management** to persist and evolve an email draft across multiple interaction turns\n",
        "\n",
        "**Pattern:**\n",
        "```\n",
        "User Request ‚Üí Draft/Update ‚Üí [Loop: Iterative Feedback] ‚Üí Human Approval ‚Üí Send Email"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0DQrW5jd_muI",
      "metadata": {
        "id": "0DQrW5jd_muI"
      },
      "source": [
        "### The Pattern You'll Master\n",
        "\n",
        "![Workflow Diagram](../../qubrid-cookbook/Assets/Images/hitl.png)\n",
        "\n",
        "Let's begin! üöÄ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RotPsR761mFV",
      "metadata": {
        "id": "RotPsR761mFV"
      },
      "source": [
        "## 1. Environment Setup\n",
        "Initialize the development environment by setting up the orchestration stack and authenticating with the Qubrid AI Platform.\n",
        "\n",
        "- **Core Orchestration**: LangGraph and LangChain for building stateful, multi-turn agent workflows.\n",
        "- **Qubrid AI Integration**: Configure `QUBRID_API_KEY` to access high-performance inference for **GPT-OSS-120b**.\n",
        "- **Environment Agnostic**: Support for both Local (`.env`) and Google Colab (`userdata`) authentication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "install",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "install",
        "outputId": "5d757b6f-5e0a-41a5-9931-629071f053e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m32 packages\u001b[0m \u001b[2min 430ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m8 packages\u001b[0m \u001b[2min 140ms\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m8 packages\u001b[0m \u001b[2min 34ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m8 packages\u001b[0m \u001b[2min 11ms\u001b[0m\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mlangchain-core\u001b[0m\u001b[2m==1.2.7\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlangchain-core\u001b[0m\u001b[2m==1.2.8\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mlangsmith\u001b[0m\u001b[2m==0.6.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlangsmith\u001b[0m\u001b[2m==0.6.8\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1morjson\u001b[0m\u001b[2m==3.11.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1morjson\u001b[0m\u001b[2m==3.11.7\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mpackaging\u001b[0m\u001b[2m==25.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpackaging\u001b[0m\u001b[2m==26.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.12.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.12.5\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.41.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.41.5\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.5\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.5.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.6.3\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!uv pip install -U langgraph langchain_core requests python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "imports",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imports",
        "outputId": "bd315cb1-c80b-4edc-ebdd-ac918d91fd4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment: Google Colab\n"
          ]
        }
      ],
      "source": [
        "# 1. Imports and Environment Setup\n",
        "import os\n",
        "import requests\n",
        "import json\n",
        "import re\n",
        "from typing import List, Optional, Any, TypedDict, Annotated\n",
        "from langchain_core.language_models import BaseChatModel\n",
        "from langchain_core.messages import (\n",
        "    BaseMessage, AIMessage, HumanMessage, ToolMessage, SystemMessage\n",
        ")\n",
        "from langchain_core.outputs import ChatResult, ChatGeneration\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
        "from pydantic import Field\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.types import interrupt, Command\n",
        "\n",
        "# Load API Key\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    QUBRID_API_KEY = userdata.get(\"QUBRID_API_KEY\")\n",
        "    print(\"Environment: Google Colab\")\n",
        "except ImportError:\n",
        "    from dotenv import load_dotenv\n",
        "    load_dotenv()\n",
        "    QUBRID_API_KEY = os.getenv(\"QUBRID_API_KEY\")\n",
        "    print(\"Environment: Local\")\n",
        "\n",
        "if not QUBRID_API_KEY:\n",
        "    raise ValueError(\"QUBRID_API_KEY not found!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "o-DYoABh2BKK",
      "metadata": {
        "id": "o-DYoABh2BKK"
      },
      "source": [
        "## 2. Setting up the LLM Client\n",
        "We implement a custom LangChain wrapper for the **gpt-oss-120b** model on Qubrid."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "chat-model",
      "metadata": {
        "id": "chat-model"
      },
      "outputs": [],
      "source": [
        "# 2. Custom Qubrid Chat Model (with corrected API parsing)\n",
        "class ChatQubrid(BaseChatModel):\n",
        "    \"\"\"Qubrid Chat Model with corrected API response parsing.\"\"\"\n",
        "\n",
        "# Qubrid model configuration and generation parameters\n",
        "    api_key: str = Field(...)\n",
        "    base_url: str = \"https://platform.qubrid.com/api/v1/qubridai/chat/completions\"\n",
        "    model_name: str = \"openai/gpt-oss-120b\"\n",
        "    temperature: float = 0.5\n",
        "    max_tokens: int = 2000\n",
        "    tools: Optional[List[dict]] = None\n",
        "\n",
        "# Identifies this custom model type for LangChain internals\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"qubrid-chat-model\"\n",
        "\n",
        "# Core generation method required by BaseChatModel.\n",
        "# Translates LangChain messages ‚Üí Qubrid API payload\n",
        "# and converts Qubrid responses ‚Üí LangChain ChatResult.\n",
        "    def _generate(self, messages: List[BaseMessage], stop: Optional[List[str]] = None, **kwargs: Any) -> ChatResult:\n",
        "# Authorization and content headers for Qubrid Chat Completion API\n",
        "        headers = {\"Authorization\": f\"Bearer {self.api_key}\", \"Content-Type\": \"application/json\"}\n",
        "\n",
        "        # Convert LangChain message objects into OpenAI-compatible\n",
        "        # role/content format expected by Qubrid API\n",
        "        payload_messages = []\n",
        "        for m in messages:\n",
        "            role = \"user\"\n",
        "            if isinstance(m, HumanMessage): role = \"user\"\n",
        "            elif isinstance(m, AIMessage): role = \"assistant\"\n",
        "            elif isinstance(m, ToolMessage): role = \"tool\"\n",
        "            elif isinstance(m, SystemMessage): role = \"system\"\n",
        "\n",
        "            msg_dict = {\"role\": role, \"content\": str(m.content)}\n",
        "            # Required to correctly associate tool responses with tool calls\n",
        "            if isinstance(m, ToolMessage):\n",
        "                msg_dict[\"tool_call_id\"] = m.tool_call_id\n",
        "            # Preserve tool call metadata for multi-step tool execution\n",
        "            if isinstance(m, AIMessage) and \"tool_calls\" in m.additional_kwargs:\n",
        "                msg_dict[\"tool_calls\"] = m.additional_kwargs[\"tool_calls\"]\n",
        "            payload_messages.append(msg_dict)\n",
        "\n",
        "        # Final request payload sent to Qubrid chat completion endpoint\n",
        "        payload = {\n",
        "            \"model\": self.model_name,\n",
        "            \"messages\": payload_messages,\n",
        "            \"temperature\": self.temperature,\n",
        "            \"max_tokens\": self.max_tokens,\n",
        "            \"stream\": False\n",
        "        }\n",
        "\n",
        "        # Attach tool schemas when the model is tool-enabled (agent mode)\n",
        "        if self.tools:\n",
        "            payload[\"tools\"] = self.tools\n",
        "\n",
        "        # Execute synchronous request to Qubrid API and fail fast on HTTP errors\n",
        "        res = requests.post(self.base_url, headers=headers, json=payload, timeout=60)\n",
        "        res.raise_for_status()\n",
        "        data = res.json()\n",
        "\n",
        "        # Qubrid response parsing:\n",
        "        # - `content` holds the assistant text output\n",
        "        # - `tool_calls` contains structured function/tool invocations (if any)\n",
        "        content = data.get(\"content\") or \"\"\n",
        "        raw_tool_calls = data.get(\"tool_calls\") or []\n",
        "\n",
        "        # Normalize tool calls into LangChain-compatible format\n",
        "        tool_calls = []\n",
        "        for tc in raw_tool_calls:\n",
        "            tool_calls.append({\n",
        "                \"name\": tc[\"function\"][\"name\"],\n",
        "                \"args\": json.loads(tc[\"function\"][\"arguments\"]),\n",
        "                \"id\": tc[\"id\"]\n",
        "            })\n",
        "\n",
        "        # Create LangChain AIMessage with both text output and tool calls\n",
        "        ai_msg = AIMessage(content=content, tool_calls=tool_calls)\n",
        "        if raw_tool_calls:\n",
        "            ai_msg.additional_kwargs[\"tool_calls\"] = raw_tool_calls\n",
        "\n",
        "        # Wrap the AI message in LangChain's ChatResult container\n",
        "        return ChatResult(generations=[ChatGeneration(message=ai_msg)])\n",
        "\n",
        "    # Enables tool binding by converting LangChain tools\n",
        "    # into OpenAI-compatible tool schemas for Qubrid\n",
        "    def bind_tools(self, tools: List[Any], **kwargs: Any) -> Any:\n",
        "        new_instance = self.model_copy()\n",
        "        new_instance.tools = [convert_to_openai_tool(t) for t in tools]\n",
        "        return new_instance\n",
        "\n",
        "llm = ChatQubrid(api_key=QUBRID_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RXzxUvo2B-fe",
      "metadata": {
        "id": "RXzxUvo2B-fe"
      },
      "source": [
        "## 3. Agent State and Tool Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "state-tools",
      "metadata": {
        "id": "state-tools"
      },
      "outputs": [],
      "source": [
        "# Agent State Definition\n",
        "\n",
        "# Represents the structured email draft maintained across turns.\n",
        "# `total=False` allows partial updates (e.g., only body changes).\n",
        "class EmailDraft(TypedDict, total=False):\n",
        "    recipient: str\n",
        "    subject: str\n",
        "    body: str\n",
        "\n",
        "\n",
        "# Shared agent state passed between LangGraph nodes.\n",
        "class AgentState(TypedDict):\n",
        "    # Conversation history managed by LangGraph.\n",
        "    # `add_messages` automatically appends new messages to state.\n",
        "    messages: Annotated[list[BaseMessage], add_messages]\n",
        "\n",
        "    # The current working email draft.\n",
        "    draft: EmailDraft\n",
        "\n",
        "    # Controls graph flow (e.g., \"draft\", \"approve\", \"send\").\n",
        "    next_action: Optional[str]\n",
        "\n",
        "# Tool Definitions\n",
        "@tool\n",
        "def update_email_draft(recipient: str, subject: str, body: str) -> str:\n",
        "    \"\"\"\n",
        "    Updates the email draft stored in agent state.\n",
        "\n",
        "    This tool is used during the drafting and refinement loop\n",
        "    and does NOT send the email.\n",
        "    \"\"\"\n",
        "    return f\"‚úÖ Draft updated: {recipient} | {subject}\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def send_email(recipient: str, subject: str, body: str) -> str:\n",
        "    \"\"\"\n",
        "    Executes the final email send action.\n",
        "\n",
        "    This tool should only be callable after passing\n",
        "    the Human-in-the-Loop (HITL) approval gate.\n",
        "    \"\"\"\n",
        "    return f\"üìß Email sent to {recipient}!\"\n",
        "\n",
        "\n",
        "# Register all tools available to the agent.\n",
        "# `send_email` is intentionally gated by human approval in the graph.\n",
        "tools = [update_email_draft, send_email]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9IA0saf2srU",
      "metadata": {
        "id": "c9IA0saf2srU"
      },
      "source": [
        "## 4. Helper Utilities & Decision Logic\n",
        "This section contains the pattern-matching utilities that extract email drafts from structured text and detect when the agent intends to \"send\" the communication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "graph",
      "metadata": {
        "id": "graph"
      },
      "outputs": [],
      "source": [
        "# 4. Graph Implementation\n",
        "SYSTEM_PROMPT = \"\"\"You are an Email Assistant. Help the user draft emails.\n",
        "\n",
        "When the user asks you to draft or update an email, respond with:\n",
        "1. A conversational message\n",
        "2. The email details in this EXACT format:\n",
        "\n",
        "DRAFT:\n",
        "To: [email]\n",
        "Subject: [subject]\n",
        "Body: [body text]\n",
        "\n",
        "When the user says \\\"send it\\\" or \\\"send now\\\", respond with:\n",
        "SEND: yes\n",
        "\n",
        "Be helpful and conversational.\"\"\"\n",
        "\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "def extract_draft_from_text(content: str) -> Optional[EmailDraft]:\n",
        "    \"\"\"Extract email draft from model's text response.\"\"\"\n",
        "    if \"DRAFT:\" not in content:\n",
        "        return None\n",
        "    draft = {}\n",
        "    to_match = re.search(r'To:\\s*([^\\n]+)', content)\n",
        "    if to_match: draft[\"recipient\"] = to_match.group(1).strip()\n",
        "    subj_match = re.search(r'Subject:\\s*([^\\n]+)', content)\n",
        "    if subj_match: draft[\"subject\"] = subj_match.group(1).strip()\n",
        "    body_match = re.search(r'Body:\\s*(.+?)(?=\\n\\n|$)', content, re.DOTALL)\n",
        "    if body_match: draft[\"body\"] = body_match.group(1).strip()\n",
        "    return draft if draft else None\n",
        "\n",
        "def should_send(content: str) -> bool:\n",
        "    return \"SEND: yes\" in content or \"send it\" in content.lower()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BMg_8vSz26-5",
      "metadata": {
        "id": "BMg_8vSz26-5"
      },
      "source": [
        "## 5. Defining Agent Nodes\n",
        "These functions represent the nodes of our graph. They receive the current state, perform a transformation (like invoking the LLM or prompting for human feedback), and return the updated state.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "u-rWsHkt3FM0",
      "metadata": {
        "id": "u-rWsHkt3FM0"
      },
      "outputs": [],
      "source": [
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "def model_node(state: AgentState):\n",
        "    \"\"\"Processes user input, updates the draft, and determines the next action.\"\"\"\n",
        "    messages = [SystemMessage(content=SYSTEM_PROMPT)] + state[\"messages\"]\n",
        "    response = llm_with_tools.invoke(messages)\n",
        "\n",
        "    draft_update = state.get(\"draft\", {})\n",
        "    if response.tool_calls:\n",
        "        for tc in response.tool_calls:\n",
        "            if tc[\"name\"] in [\"update_email_draft\", \"send_email\"]:\n",
        "                draft_update = {**draft_update, **tc[\"args\"]}\n",
        "    else:\n",
        "        extracted = extract_draft_from_text(response.content)\n",
        "        if extracted: draft_update = {**draft_update, **extracted}\n",
        "\n",
        "    next_action = \"send_email\" if should_send(response.content) and draft_update else None\n",
        "    return {\"messages\": [response], \"draft\": draft_update, \"next_action\": next_action}\n",
        "\n",
        "def send_email_node(state: AgentState):\n",
        "    \"\"\"Secure HITL node. Pauses execution for human approval via interrupt().\"\"\"\n",
        "    draft = state[\"draft\"]\n",
        "    print(\"\\n\" + \"=\"*60 + \"\\nüìß READY TO SEND EMAIL\\n\" + \"=\"*60)\n",
        "    print(f\"To: {draft.get('recipient', 'N/A')}\\nSubject: {draft.get('subject', 'N/A')}\")\n",
        "    print(f\"Body:\\n{draft.get('body', 'N/A')[:200]}...\\n\" + \"=\"*60)\n",
        "\n",
        "    decision = interrupt(\"Approve sending this email?\")\n",
        "\n",
        "    if isinstance(decision, str) and decision.lower().strip() == \"yes\":\n",
        "        return {\"messages\": [AIMessage(content=\"‚úÖ Email sent successfully!\")]}\n",
        "    else:\n",
        "        return {\"messages\": [AIMessage(content=\"‚ùå Send cancelled. You can continue editing.\")]}\n",
        "\n",
        "def router(state: AgentState):\n",
        "    \"\"\"Conditional logic to route to the HITL gate or end the turn.\"\"\"\n",
        "    return \"send_email\" if state.get(\"next_action\") == \"send_email\" else END"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a45Wca0Q3TnM",
      "metadata": {
        "id": "a45Wca0Q3TnM"
      },
      "source": [
        "## 6. Graph Compilation & Orchestration\n",
        "The final step is to assemble the nodes and edges into a stateful workflow. We use a `MemorySaver` to provide persistence, allowing the agent to remember the email draft across multiple user turns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "qIGJqIHC3X7k",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIGJqIHC3X7k",
        "outputId": "02488a47-a679-4ed1-973e-870a9c8b9532"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ HITL Email Agent compiled successfully!\n"
          ]
        }
      ],
      "source": [
        "# 1. Initialize Graph\n",
        "builder = StateGraph(AgentState)\n",
        "\n",
        "# 2. Add Nodes\n",
        "builder.add_node(\"model\", model_node)\n",
        "builder.add_node(\"send_email\", send_email_node)\n",
        "\n",
        "# 3. Define Edges & Routing\n",
        "builder.add_edge(START, \"model\")\n",
        "builder.add_conditional_edges(\n",
        "    \"model\",\n",
        "    router,\n",
        "    {\n",
        "        \"send_email\": \"send_email\",\n",
        "        END: END\n",
        "    }\n",
        ")\n",
        "builder.add_edge(\"send_email\", END)\n",
        "\n",
        "# 4. Compile with Persistence\n",
        "memory = MemorySaver()\n",
        "chatbot = builder.compile(checkpointer=memory)\n",
        "\n",
        "print(\"‚úÖ HITL Email Agent compiled successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pwRtQmuW7D8E",
      "metadata": {
        "id": "pwRtQmuW7D8E"
      },
      "source": [
        "## Workflow Visualization\n",
        "The following diagram visualizes the agent's internal state machine. It illustrates the logic flow from user input to the iterative drafting loop, and finally to the mandatory **Human-in-the-Loop Gate** that protects the send sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "Z472tJH97KJ-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "Z472tJH97KJ-",
        "outputId": "0efaa910-6007-4e7e-bb04-5bc5f18b2973"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import Image\n",
        "Image(chatbot.get_graph().draw_mermaid_png())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "examples",
      "metadata": {
        "id": "examples"
      },
      "source": [
        "# 7. Usage Examples\n",
        "\n",
        "The following cells demonstrate the complete HITL workflow."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_nUK9VX-3inq",
      "metadata": {
        "id": "_nUK9VX-3inq"
      },
      "source": [
        "**Example 1: Initial Drafting** ‚Äî The agent creates a structured email draft based on a simple natural language request."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "example-1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "example-1",
        "outputId": "5d366f4c-6068-457f-e3fa-a706e173305b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: Draft an email to john@example.com about onboarding documents\n",
            "\n",
            "Assistant: Sure thing! Here‚Äôs a draft you can use:\n",
            "\n",
            "DRAFT:\n",
            "To: john@example.com\n",
            "Subject: Onboarding Documents Needed\n",
            "Body: Hi John,\n",
            "\n",
            "Welcome aboard! To complete your onboarding process, we‚Äôll need a few documents from you:\n",
            "\n",
            "- Signed offer letter\n",
            "- Government‚Äëissued ID (e.g., passport or driver‚Äôs license)\n",
            "- Completed tax forms (W‚Äë4)\n",
            "- Direct deposit information\n",
            "\n",
            "If you could send these over by **[insert deadline, e.g., Friday, February 14]**, that would keep everything on track. Feel free to let me know if you have any questions or need assistance with any of the forms.\n",
            "\n",
            "Thanks, and we look forward to having you on the team!\n",
            "\n",
            "Best regards,\n",
            "[Your Name]\n",
            "[Your Position]\n",
            "[Your Contact Information]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Example 1: Initial Draft\n",
        "config = {\"configurable\": {\"thread_id\": \"demo-session\"}}\n",
        "\n",
        "print(\"User: Draft an email to john@example.com about onboarding documents\\n\")\n",
        "events = chatbot.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"Draft an email to john@example.com about onboarding documents\")]},\n",
        "    config=config,\n",
        "    stream_mode=\"values\"\n",
        ")\n",
        "\n",
        "for event in events:\n",
        "    last_msg = event[\"messages\"][-1]\n",
        "    if isinstance(last_msg, AIMessage) and last_msg.content:\n",
        "        print(f\"Assistant: {last_msg.content}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ESmyA-Yt3tyT",
      "metadata": {
        "id": "ESmyA-Yt3tyT"
      },
      "source": [
        "**Example 2: Iterative Refinement** ‚Äî Demonstrates the agent's ability to process feedback and update specific draft fields while maintaining conversation state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "example-2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "example-2",
        "outputId": "18694807-4bfa-4cac-db51-2116a9317b59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: Make it more formal\n",
            "\n",
            "Assistant: Sure thing! Here‚Äôs a more formal version of the email:\n",
            "\n",
            "DRAFT:\n",
            "To: john@example.com\n",
            "Subject: Submission of Required Onboarding Documentation\n",
            "Body: Dear Mr.‚ÄØ[Last Name],\n",
            "\n",
            "I hope this message finds you well. In preparation for your upcoming start date with [Company Name], we kindly request that you provide the following onboarding documents at your earliest convenience:\n",
            "\n",
            "- Signed offer letter  \n",
            "- Government‚Äëissued identification (e.g., passport or driver‚Äôs license)  \n",
            "- Completed tax forms (e.g., IRS Form W‚Äë4)  \n",
            "- Direct deposit authorization information  \n",
            "\n",
            "Please submit the aforementioned items no later than **[insert deadline, e.g., Friday, February‚ÄØ14]** to ensure a seamless transition and timely processing of your employment records. Should you have any questions or require assistance with the documentation, do not hesitate to contact me directly.\n",
            "\n",
            "Thank you for your prompt attention to this matter. We look forward to welcoming you to the team.\n",
            "\n",
            "Sincerely,\n",
            "\n",
            "[Your Full Name]  \n",
            "[Your Title]  \n",
            "[Company Name]  \n",
            "[Phone Number]  \n",
            "[Email Address]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Example 2: Iterative Refinement\n",
        "print(\"User: Make it more formal\\n\")\n",
        "events = chatbot.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"Make it more formal\")]},\n",
        "    config=config,\n",
        "    stream_mode=\"values\"\n",
        ")\n",
        "\n",
        "for event in events:\n",
        "    last_msg = event[\"messages\"][-1]\n",
        "    if isinstance(last_msg, AIMessage) and last_msg.content:\n",
        "        print(f\"Assistant: {last_msg.content}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nCko4tEL3y5X",
      "metadata": {
        "id": "nCko4tEL3y5X"
      },
      "source": [
        "**Example 3: Triggering the HITL Gate** ‚Äî The user requests a high-privilege action (\"Send\"), causing the graph to pause at a mandatory security interrupt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "example-3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "example-3",
        "outputId": "6b0ff713-41df-4faa-c0ed-8c4c625d33fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: Send it now\n",
            "\n",
            "Assistant: SEND: yes\n",
            "\n",
            "\n",
            "============================================================\n",
            "üìß READY TO SEND EMAIL\n",
            "============================================================\n",
            "To: john@example.com\n",
            "Subject: Submission of Required Onboarding Documentation\n",
            "Body:\n",
            "Dear Mr.‚ÄØ[Last Name],...\n",
            "============================================================\n",
            "Assistant: SEND: yes\n",
            "\n",
            "‚è∏Ô∏è  Execution paused for HITL approval\n"
          ]
        }
      ],
      "source": [
        "# Example 3: Trigger Send (HITL Approval)\n",
        "print(\"User: Send it now\\n\")\n",
        "events = chatbot.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"Send it now\")]},\n",
        "    config=config,\n",
        "    stream_mode=\"values\"\n",
        ")\n",
        "\n",
        "for event in events:\n",
        "    last_msg = event[\"messages\"][-1]\n",
        "    if isinstance(last_msg, AIMessage) and last_msg.content:\n",
        "        print(f\"Assistant: {last_msg.content}\\n\")\n",
        "\n",
        "# Check for interrupt\n",
        "state = chatbot.get_state(config)\n",
        "if state.tasks:\n",
        "    for task in state.tasks:\n",
        "        if task.interrupts:\n",
        "            print(\"‚è∏Ô∏è  Execution paused for HITL approval\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "q2XbWG7f35fi",
      "metadata": {
        "id": "q2XbWG7f35fi"
      },
      "source": [
        "**Example 4: Human Authority Approval** ‚Äî The \"Authority\" resumes the graph execution with an explicit decision to finalize the workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "example-4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "example-4",
        "outputId": "caf063df-824b-4eb6-e128-418524b2e8d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üë§ Approve sending? (yes/no): yes\n",
            "\n",
            "Assistant: ‚ùå Send cancelled. You can continue editing.\n"
          ]
        }
      ],
      "source": [
        "# Example 4: Human Approval\n",
        "decision = input(\"üë§ Approve sending? (yes/no): \")\n",
        "result = chatbot.invoke(Command(resume=decision), config=config)\n",
        "print(f\"\\nAssistant: {result['messages'][-1].content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_sEqkW5bxw1J",
      "metadata": {
        "id": "_sEqkW5bxw1J"
      },
      "source": [
        "**Example 5: Rejection & Revision**\n",
        "This example demonstrates the full HITL cycle: drafting, requesting to send, human rejection, iterative revision, and final approval."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0Q4qWGsZ5N6a",
      "metadata": {
        "id": "0Q4qWGsZ5N6a"
      },
      "source": [
        "*Step 1: The agent drafts an email and triggers the \"Send\" sequence, which hits the mandatory HITL pause.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "QkFLpZTLxxh5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkFLpZTLxxh5",
        "outputId": "8e28e4f8-5e09-4516-d2a1-1b3d1256b2a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: Draft an email to my manager about the project update\n",
            "\n",
            "Assistant: Sure thing! Here‚Äôs a concise draft you can tweak as needed before sending it to your manager.\n",
            "\n",
            "DRAFT:\n",
            "To: manager@example.com\n",
            "Subject: Project Update ‚Äì [Project Name] ‚Äì [Date]\n",
            "Body: Hi [Manager‚Äôs Name],\n",
            "\n",
            "I wanted to provide a quick update on the [Project Name] as of [Date].\n",
            "\n",
            "**Progress:**  \n",
            "- Completed [Milestone/Task 1] and [Milestone/Task 2].  \n",
            "- Currently on track with [Current Phase/Task], expected to finish by [Target Date].\n",
            "\n",
            "**Upcoming Work:**  \n",
            "- Next steps include [Upcoming Task 1] and [Upcoming Task 2].  \n",
            "- We‚Äôre coordinating with [Team/Department] to ensure smooth hand‚Äëoff.\n",
            "\n",
            "**Risks/Issues:**  \n",
            "- [Brief description of any risk or issue] and our mitigation plan is [Mitigation Strategy].\n",
            "\n",
            "Please let me know if you‚Äôd like more detail on any of these points or have any feedback.\n",
            "\n",
            "Thanks,  \n",
            "[Your Name]  \n",
            "[Your Position]  \n",
            "\n",
            "Feel free to adjust the placeholders (e.g., manager‚Äôs name, project specifics) to fit your situation. Let me know if you‚Äôd like any changes!\n",
            "\n",
            "User: Send it now\n",
            "\n",
            "Assistant: SEND: yes\n",
            "\n",
            "============================================================\n",
            "üìß READY TO SEND EMAIL\n",
            "============================================================\n",
            "To: manager@example.com\n",
            "Subject: Project Update ‚Äì [Project Name] ‚Äì [Date]\n",
            "Body:\n",
            "Hi [Manager‚Äôs Name],...\n",
            "============================================================\n",
            "Assistant: SEND: yes\n",
            "\n",
            "‚è∏Ô∏è  Graph paused at: ('send_email',)\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Initial Draft and Send Request\n",
        "config_rejection = {\"configurable\": {\"thread_id\": \"rejection-session-1\"}}\n",
        "print(\"User: Draft an email to my manager about the project update\\n\")\n",
        "for event in chatbot.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"Draft an email to my manager about the project update\")]},\n",
        "    config=config_rejection, stream_mode=\"values\"\n",
        "):\n",
        "    last_msg = event[\"messages\"][-1]\n",
        "    if isinstance(last_msg, AIMessage) and last_msg.content:\n",
        "        print(f\"Assistant: {last_msg.content}\\n\")\n",
        "\n",
        "print(\"User: Send it now\\n\")\n",
        "for event in chatbot.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"Send it now\")]},\n",
        "    config=config_rejection, stream_mode=\"values\"\n",
        "):\n",
        "    last_msg = event[\"messages\"][-1]\n",
        "    if isinstance(last_msg, AIMessage) and last_msg.content:\n",
        "        print(f\"Assistant: {last_msg.content}\")\n",
        "\n",
        "# Check if paused\n",
        "state = chatbot.get_state(config_rejection)\n",
        "if state.next:\n",
        "    print(f\"\\n‚è∏Ô∏è  Graph paused at: {state.next}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kniVvBSo5RK8",
      "metadata": {
        "id": "kniVvBSo5RK8"
      },
      "source": [
        "*Step 2: The human supervisor rejects the action (\"no\"), causing the agent to safely cancel the send and remain in editing mode.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "Ro5KiS77x010",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ro5KiS77x010",
        "outputId": "16fdc1eb-3091-4792-fb4b-802467c9f54e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Human Authority: no\n",
            "\n",
            "\n",
            "============================================================\n",
            "üìß READY TO SEND EMAIL\n",
            "============================================================\n",
            "To: manager@example.com\n",
            "Subject: Project Update ‚Äì [Project Name] ‚Äì [Date]\n",
            "Body:\n",
            "Hi [Manager‚Äôs Name],...\n",
            "============================================================\n",
            "Assistant: ‚ùå Send cancelled. You can continue editing.\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Human Authority Rejects\n",
        "print(\"Human Authority: no\\n\")\n",
        "chatbot.invoke(Command(resume=\"no\"), config=config_rejection)\n",
        "\n",
        "# Show that the draft is still preserved and we are back in editing\n",
        "state = chatbot.get_state(config_rejection)\n",
        "print(f\"Assistant: {state.values['messages'][-1].content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MrcdmVqw5Tft",
      "metadata": {
        "id": "MrcdmVqw5Tft"
      },
      "source": [
        "*Step 3: The user provides corrective feedback to the draft and attempts a second send request.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "yxeTTcuCx8Dl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxeTTcuCx8Dl",
        "outputId": "4df72140-e89e-4b20-a3be-4ebd0b4dd42c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: Make it much more formal and add a bullet point about the budget status.\n",
            "\n",
            "Assistant: Here‚Äôs a more formal version with a bullet point for the budget status:\n",
            "\n",
            "DRAFT:\n",
            "To: [Manager‚Äôs Email]\n",
            "Subject: Formal Project Update ‚Äì [Project Name] ‚Äì [Date]\n",
            "\n",
            "Body:\n",
            "Dear [Manager‚Äôs Name],\n",
            "\n",
            "I am writing to provide a comprehensive update on the status of the **[Project Name]** as of **[Date]**.\n",
            "\n",
            "- **Progress to Date:**  \n",
            "  ‚Ä¢ Completion of [Milestone/Task 1] and [Milestone/Task 2].  \n",
            "  ‚Ä¢ Current activities focus on [Current Phase/Task], with an anticipated completion date of [Target Date].\n",
            "\n",
            "- **Budget Status:**  \n",
            "  ‚Ä¢ The project remains within the approved budget, with actual expenditures to date totaling **$[Amount]**, representing **[X]%** of the total allocated funds.  \n",
            "  ‚Ä¢ Forecasted spend for the remaining phases is **$[Amount]**, and we anticipate no variance beyond the approved contingency.\n",
            "\n",
            "- **Upcoming Work:**  \n",
            "  ‚Ä¢ Planned tasks for the next reporting period include [Upcoming Task 1] and [Upcoming Task 2].  \n",
            "  ‚Ä¢ Coordination with [Team/Department] will continue to ensure seamless hand‚Äëoffs and adherence to timelines.\n",
            "\n",
            "- **Risks and Mitigation Measures:**  \n",
            "  ‚Ä¢ [Brief description of any identified risk or issue].  \n",
            "  ‚Ä¢ Mitigation strategy: [Mitigation Plan].\n",
            "\n",
            "Please let me know if you require further detail on any of the above items or have additional guidance.\n",
            "\n",
            "Thank you for your continued support.\n",
            "\n",
            "Sincerely,\n",
            "\n",
            "[Your Full Name]  \n",
            "[Your Position]  \n",
            "[Your Department]  \n",
            "[Your Contact Information]\n",
            "\n",
            "User: Okay, send it now\n",
            "\n",
            "Assistant: SEND: yes\n",
            "\n",
            "============================================================\n",
            "üìß READY TO SEND EMAIL\n",
            "============================================================\n",
            "To: [Manager‚Äôs Email]\n",
            "Subject: Formal Project Update ‚Äì [Project Name] ‚Äì [Date]\n",
            "Body:\n",
            "Dear [Manager‚Äôs Name],...\n",
            "============================================================\n",
            "Assistant: SEND: yes\n",
            "\n",
            "‚è∏Ô∏è  Graph paused for revised approval at: ('send_email',)\n"
          ]
        }
      ],
      "source": [
        "# Step 3: User requests revision and tries to send again\n",
        "print(\"User: Make it much more formal and add a bullet point about the budget status.\\n\")\n",
        "for event in chatbot.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"Make it much more formal and add a bullet point about the budget status.\")]},\n",
        "    config=config_rejection, stream_mode=\"values\"\n",
        "):\n",
        "    last_msg = event[\"messages\"][-1]\n",
        "    if isinstance(last_msg, AIMessage) and last_msg.content:\n",
        "        print(f\"Assistant: {last_msg.content}\\n\")\n",
        "\n",
        "print(\"User: Okay, send it now\\n\")\n",
        "for event in chatbot.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"Okay, send it now\")]},\n",
        "    config=config_rejection, stream_mode=\"values\"\n",
        "):\n",
        "    last_msg = event[\"messages\"][-1]\n",
        "    if isinstance(last_msg, AIMessage) and last_msg.content:\n",
        "        print(f\"Assistant: {last_msg.content}\")\n",
        "\n",
        "# Check for interrupt again\n",
        "state = chatbot.get_state(config_rejection)\n",
        "if state.next:\n",
        "    print(f\"\\n‚è∏Ô∏è  Graph paused for revised approval at: {state.next}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lJI_Q0s55VzX",
      "metadata": {
        "id": "lJI_Q0s55VzX"
      },
      "source": [
        "*Step 4: The human authority grants final approval (\"yes\"), allowing the graph to proceed and finalize the action.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "ZC82y6Wbx-Jc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC82y6Wbx-Jc",
        "outputId": "b7bb6089-bc95-433c-a8c8-e04728c7bcbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Human Authority: yes\n",
            "\n",
            "\n",
            "============================================================\n",
            "üìß READY TO SEND EMAIL\n",
            "============================================================\n",
            "To: [Manager‚Äôs Email]\n",
            "Subject: Formal Project Update ‚Äì [Project Name] ‚Äì [Date]\n",
            "Body:\n",
            "Dear [Manager‚Äôs Name],...\n",
            "============================================================\n",
            "Assistant: ‚úÖ Email sent successfully!\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Final Approval\n",
        "print(\"Human Authority: yes\\n\")\n",
        "result = chatbot.invoke(Command(resume=\"yes\"), config=config_rejection)\n",
        "\n",
        "print(f\"Assistant: {result['messages'][-1].content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1jm1D0Sq4Jes",
      "metadata": {
        "id": "1jm1D0Sq4Jes"
      },
      "source": [
        "**Pattern Architecture:**\n",
        "\n",
        "`User Prompt` ‚Üí `[Loop: Draft ‚Üî Refine]` ‚Üí `HITL Gate (Interrupt)` ‚Üí `Human Approval` ‚Üí `Execute Send`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rfnDvexi48qf",
      "metadata": {
        "id": "rfnDvexi48qf"
      },
      "source": [
        "By leveraging **LangGraph** and **Qubrid AI**, we've built a system that moves beyond simple linear AI scripts to a robust, state-machine architecture:\n",
        "- **State Persistence**: Maintaining a consistent [EmailDraft](cci:2://file:///Users/kannanpathania/Documents/QubridAI/Second_Notebook/working_hitl_agent.py:124:0-127:13) schema (Recipient, Subject, Body) across multiple turns, even when an action is rejected by the human.\n",
        "- **Protected Orchestration**: Decoupling the high-intelligence drafting logic from sensitive \"Send\" actions via a mandatory HITL security gate.\n",
        "- **Non-Linear Workflows**: Replacing fragile one-step commands with a dynamic feedback loop that routes between drafting, refinement, and final execution.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PWbHiwPA5JgX",
      "metadata": {
        "id": "PWbHiwPA5JgX"
      },
      "source": [
        "## Start Building Intelligent Agents ‚ö°\n",
        "\n",
        "[üîë Get Your API Key](https://platform.qubrid.com/signup) ¬∑\n",
        "[ü§ñ Explore Available Models](https://docs.platform.qubrid.com/inferencing/Serverless%20Models) ¬∑\n",
        "[üèè Try the Playground](https://platform.qubrid.com/playground)\n",
        "\n",
        "__Build, deploy, and scale agentic workflows with Qubrid AI.__"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Second_Notebook",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
