{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YrcEgRUATG5"
      },
      "source": [
        "# Youtube Agent using LangGraph and Qubrid AI\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/QubridAI-Inc/qubrid-cookbook/blob/main/Notebooks/Langgraph_Youtube_Agent.ipynb)\n",
        "\n",
        "![Qubrid x Langgraph](../../qubrid-cookbook/Assets/Images/Langgraph_x_Qubrid.png)\n",
        "\n",
        "This notebook shows how to build parallel agent workflows with LangGraph to turn YouTube videos into structured intelligence reports.\n",
        "\n",
        "- **Whisper Large V3** transcribes audio, and **GPT-OSS-120b** generates summaries and insights, both hosted on the **Qubrid AI Platform** for low-latency inference.\n",
        "\n",
        "- A fan-out/fan-in architecture enables concurrent execution and reliable shared state across parallel nodes.\n",
        "\n",
        "**Pattern:**\n",
        "```\n",
        "URL â†’ Transcribe â†’ [Parallel: Chapters & Summary] â†’ PDF Synthesis\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr6fZEDmRV8k"
      },
      "source": [
        "### The Pattern You'll Master\n",
        "\n",
        "<img\n",
        "  src=\"https://drive.google.com/uc?export=view&id=1CdU8-9t5E1KsJ0Lpth_QcJxtNPEeThPg\"\n",
        "  alt=\"Parallel Workflow Pattern\"\n",
        "  width=\"500\"\n",
        "/>\n",
        "\n",
        "Let's begin! ðŸš€"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYAVIHzEATG6"
      },
      "source": [
        "## 1. Environment Setup\n",
        "Set up the development environment by initializing the orchestration stack and authenticating with Qubrid AI.\n",
        "\n",
        "- Core Orchestration: LangGraph & LangChain for stateful agent workflows.\n",
        "\n",
        "- Media & PDF Tools: yt-dlp for audio extraction, fpdf2 for report generation.\n",
        "\n",
        "- Qubrid AI Integration: Configure QUBRID_API_KEY to access hosted Whisper Large V3 and GPT-OSS-120b.\n",
        "\n",
        "- Environment Agnostic: Auto-detects Local or Google Colab for seamless execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qo3y-Y6TATG7",
        "outputId": "6cf8a074-847f-4776-ddb0-3a6278d3df15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m37 packages\u001b[0m \u001b[2min 403ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m11 packages\u001b[0m \u001b[2min 436ms\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m9 packages\u001b[0m \u001b[2min 31ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m11 packages\u001b[0m \u001b[2min 42ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfpdf2\u001b[0m\u001b[2m==2.8.5\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mlangchain-core\u001b[0m\u001b[2m==1.2.7\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlangchain-core\u001b[0m\u001b[2m==1.2.8\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mlangsmith\u001b[0m\u001b[2m==0.6.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlangsmith\u001b[0m\u001b[2m==0.6.8\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1morjson\u001b[0m\u001b[2m==3.11.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1morjson\u001b[0m\u001b[2m==3.11.7\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mpackaging\u001b[0m\u001b[2m==25.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpackaging\u001b[0m\u001b[2m==26.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==11.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==12.1.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.12.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.12.5\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.41.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.41.5\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.5\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.5.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.6.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1myt-dlp\u001b[0m\u001b[2m==2026.1.31\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!uv pip install -U langgraph langchain_core yt-dlp fpdf2 requests python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bz40y8h1ATG7",
        "outputId": "329000e1-62f5-46be-8c57-543eb6c3d19e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment: Google Colab detected.\n"
          ]
        }
      ],
      "source": [
        "#Import required libraries\n",
        "import os\n",
        "import re\n",
        "import requests\n",
        "import json\n",
        "import time, random\n",
        "from typing import List, Optional, Any, TypedDict, Iterator\n",
        "from langchain_core.language_models import BaseChatModel\n",
        "from langchain_core.messages import BaseMessage, AIMessage, HumanMessage, AIMessageChunk\n",
        "from langchain_core.outputs import ChatResult, ChatGeneration, ChatGenerationChunk\n",
        "from pydantic import Field\n",
        "from langgraph.graph import StateGraph, END\n",
        "import yt_dlp\n",
        "from fpdf import FPDF\n",
        "\n",
        "## Load QUBRID_API_KEY by automatically detecting and handling Colab vs local environments\n",
        "try:\n",
        "    # Standard for Google Colab\n",
        "    from google.colab import userdata\n",
        "    QUBRID_API_KEY = userdata.get('QUBRID_API_KEY')\n",
        "    print(\"Environment: Google Colab detected.\")\n",
        "except ImportError:\n",
        "    # Standard for local development\n",
        "    from dotenv import load_dotenv\n",
        "    load_dotenv()\n",
        "    QUBRID_API_KEY = os.getenv(\"QUBRID_API_KEY\")\n",
        "    print(\"Environment: Local environment detected.\")\n",
        "\n",
        "if not QUBRID_API_KEY:\n",
        "    raise ValueError(\"QUBRID_API_KEY missing. Please set it in your environment.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rI5S-dIPATG8"
      },
      "source": [
        "## 2. Setting up the LLM Client\n",
        "We implement a custom LangChain wrapper for the **gpt-oss-120b** model on Qubrid."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zVXPLeIZATG8"
      },
      "outputs": [],
      "source": [
        "# Custom LangChain-compatible chat model wrapper for Qubrid AI with streaming and non-streaming support\n",
        "class ChatQubrid(BaseChatModel):\n",
        "    \"\"\"Modular Custom Chat Model for Qubrid AI supporting Streaming.\"\"\"\n",
        "    api_key: str = Field(..., description=\"Your Qubrid API Key\")\n",
        "    base_url: str = \"https://platform.qubrid.com/api/v1/qubridai/chat/completions\"\n",
        "    model_name: str = \"openai/gpt-oss-120b\"\n",
        "    temperature: float = 0.3\n",
        "    max_tokens: int = 1500\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"qubrid-chat-model\"\n",
        "\n",
        "# Centralized request construction to keep streaming and non-streaming logic consistent\n",
        "    def _prepare_payload(self, messages: List[BaseMessage], stream: bool = False) -> tuple:\n",
        "        \"\"\"Shared logic to build headers and JSON payload.\"\"\"\n",
        "        headers = {\n",
        "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "        payload = {\n",
        "            \"model\": self.model_name,\n",
        "            \"messages\": [{\"role\": \"user\", \"content\": m.content} for m in messages],\n",
        "            \"temperature\": self.temperature,\n",
        "            \"max_tokens\": self.max_tokens,\n",
        "            \"stream\": stream\n",
        "        }\n",
        "        return headers, payload\n",
        "\n",
        "# Execute standard (non-streaming) chat completion request\n",
        "    def _generate(self, messages: List[BaseMessage], stop: Optional[List[str]] = None, **kwargs: Any) -> ChatResult:\n",
        "        \"\"\"Handles non-streaming requests with status validation.\"\"\"\n",
        "        headers, payload = self._prepare_payload(messages, stream=False)\n",
        "\n",
        "        res = requests.post(self.base_url, headers=headers, json=payload, timeout=60)\n",
        "\n",
        "        if res.status_code != 200:\n",
        "            error_msg = f\"[Qubrid Error] API returned {res.status_code}. Response: {res.text[:500]}\"\n",
        "            print(error_msg)\n",
        "            raise ValueError(error_msg)\n",
        "\n",
        "        try:\n",
        "            data = res.json()\n",
        "            # Support both Qubrid direct content and OpenAI-compatible choice structures\n",
        "            content = data.get(\"content\") or data.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\")\n",
        "            return ChatResult(generations=[ChatGeneration(message=AIMessage(content=str(content)))])\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Failed to process response: {str(e)}. Raw text: {res.text[:500]}\")\n",
        "\n",
        "# Parse Server-Sent Events (SSE) stream and yield tokens incrementally\n",
        "    def _stream(self, messages: List[BaseMessage], stop: Optional[List[str]] = None, **kwargs: Any) -> Iterator[ChatGenerationChunk]:\n",
        "        \"\"\"Handles streaming responses using Server-Sent Events (SSE).\"\"\"\n",
        "        headers, payload = self._prepare_payload(messages, stream=True)\n",
        "\n",
        "        res = requests.post(self.base_url, headers=headers, json=payload, timeout=60, stream=True)\n",
        "        res.raise_for_status()\n",
        "\n",
        "        for line in res.iter_lines():\n",
        "            if not line: continue\n",
        "            decoded_line = line.decode('utf-8')\n",
        "            if decoded_line.startswith(\"data: \"):\n",
        "                data_str = decoded_line[len(\"data: \"):]\n",
        "                if data_str.strip() == \"[DONE]\": break\n",
        "                try:\n",
        "                    data = json.loads(data_str)\n",
        "                    delta = data.get(\"choices\", [{}])[0].get(\"delta\", {}).get(\"content\", \"\")\n",
        "                    if delta:\n",
        "                        yield ChatGenerationChunk(message=AIMessageChunk(content=delta))\n",
        "                except json.JSONDecodeError:\n",
        "                    continue\n",
        "\n",
        "llm = ChatQubrid(api_key=QUBRID_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rugWqYZbATG8"
      },
      "source": [
        "## 3. Utility Functions\n",
        " Utility helpers for audio extraction, PDF-safe text normalization, and structured JSON parsing\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xKuQkO_xATG8"
      },
      "outputs": [],
      "source": [
        "# Utility: Download and extract high-quality audio from a YouTube video\n",
        "def extract_audio_from_youtube(url: str) -> str:\n",
        "    \"\"\"\n",
        "    Standalone utility function for audio extraction.\n",
        "    Optimized for headless environments (like Colab) using the 'android' player client\n",
        "    to bypass signature/sign-in requirements.\n",
        "    \"\"\"\n",
        "    print(f\"[Tool] Extracting audio from YouTube: {url}\")\n",
        "    output_base = \"audio\"\n",
        "    output_file = f\"{output_base}.m4a\"\n",
        "\n",
        "    if os.path.exists(output_file):\n",
        "        os.remove(output_file)\n",
        "\n",
        "    ydl_opts = {\n",
        "        \"format\": \"bestaudio/best\",\n",
        "        \"outtmpl\": f\"{output_base}.%(ext)s\",\n",
        "        \"quiet\": True,\n",
        "        \"no_warnings\": True,\n",
        "        \"nocheckcertificate\": True,\n",
        "        \"user_agent\": \"Mozilla/5.0 (Linux; Android 10; K) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Mobile Safari/537.36\",\n",
        "        \"referer\": \"https://www.youtube.com/\",\n",
        "        \"extractor_args\": {\n",
        "            \"youtube\": {\n",
        "                \"player_client\": [\"android\"],\n",
        "                \"skip\": [\"hls\", \"dash\"],\n",
        "            }\n",
        "        },\n",
        "        \"postprocessors\": [{\n",
        "            \"key\": \"FFmpegExtractAudio\",\n",
        "            \"preferredcodec\": \"m4a\",\n",
        "        }],\n",
        "    }\n",
        "\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download([url])\n",
        "\n",
        "    return output_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0mdEVLuM75ZE"
      },
      "outputs": [],
      "source": [
        "# Utility: Normalize text for PDF-safe Latin-1 encoding\n",
        "def sanitize_text_for_pdf(text: str) -> str:\n",
        "    \"\"\"Converts high-unicode characters to safe Latin-1 equivalents.\"\"\"\n",
        "    if not text: return \"\"\n",
        "    mapping = {\"\\u2013\": \"-\", \"\\u2014\": \"--\", \"\\u2018\": \"'\", \"\\u2019\": \"'\", \"\\u201c\": '\"', \"\\u201d\": '\"', \"\\u2022\": \"*\", \"\\u2026\": \"...\"}\n",
        "    for char, replacement in mapping.items():\n",
        "        text = text.replace(char, replacement)\n",
        "    return text.encode(\"latin-1\", \"ignore\").decode(\"latin-1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "goJIIEa677Kl"
      },
      "outputs": [],
      "source": [
        "# Utility: Extract the first valid JSON block from mixed or noisy text output\n",
        "def extract_json_from_text(text: str):\n",
        "    \"\"\"Extracts the first JSON array/object block from a string, ignoring leading/trailing chatter.\"\"\"\n",
        "    try:\n",
        "        start = text.find('[')\n",
        "        end = text.rfind(']') + 1\n",
        "        if start != -1 and end != 0:\n",
        "            json_str = text[start:end]\n",
        "            return json.loads(json_str)\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"[Log] Regex Extraction Failed: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGbLCUTo9Q50"
      },
      "source": [
        "Utility functions for synthesizer_node:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "psn_ospj8x2H"
      },
      "outputs": [],
      "source": [
        "# Initializes a PDF document with a title, ready for adding report content.\n",
        "from fpdf import FPDF\n",
        "def initialize_pdf(title: str = \"Video Intelligence Report\") -> FPDF:\n",
        "    \"\"\"\n",
        "    Initializes a PDF document and renders the report title.\n",
        "    \"\"\"\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "\n",
        "    pdf.set_font(\"Helvetica\", \"B\", 26)\n",
        "    pdf.cell(0, 25, title, new_x=\"LMARGIN\", new_y=\"NEXT\", align=\"C\")\n",
        "    pdf.ln(8)\n",
        "\n",
        "    return pdf\n",
        "\n",
        "# Renders the video timeline section in the PDF using timestamped chapter data.\n",
        "def render_timeline_section(pdf: FPDF, timestamps: str):\n",
        "    \"\"\"\n",
        "    Renders the video timeline (timestamped chapters) section.\n",
        "    Accepts raw or JSON-formatted timestamp data.\n",
        "    \"\"\"\n",
        "    pdf.set_font(\"Helvetica\", \"B\", 18)\n",
        "    pdf.set_text_color(0, 102, 204)\n",
        "    pdf.cell(0, 15, \"Video Timeline\", new_x=\"LMARGIN\", new_y=\"NEXT\")\n",
        "\n",
        "    chapters = extract_json_from_text(timestamps)\n",
        "\n",
        "    if chapters and isinstance(chapters, list):\n",
        "        pdf.set_font(\"Helvetica\", \"\", 11)\n",
        "        pdf.set_text_color(0, 0, 0)\n",
        "\n",
        "        with pdf.table(col_widths=(30, 160), borders_layout=\"SINGLE_TOP_LINE\") as table:\n",
        "            header = table.row()\n",
        "            header.cell(\"TIME\")\n",
        "            header.cell(\"TOPIC\")\n",
        "\n",
        "            for item in chapters:\n",
        "                row = table.row()\n",
        "                row.cell(sanitize_text_for_pdf(str(item.get(\"time\", \"\"))))\n",
        "                row.cell(sanitize_text_for_pdf(str(item.get(\"topic\", \"\"))))\n",
        "    else:\n",
        "        pdf.set_font(\"Helvetica\", \"I\", 10)\n",
        "        pdf.set_text_color(80, 80, 80)\n",
        "        pdf.multi_cell(0, 7, sanitize_text_for_pdf(timestamps))\n",
        "\n",
        "    pdf.ln(10)\n",
        "\n",
        "# Renders the executive summary section in the PDF from structured or raw summary text.\n",
        "def render_summary_section(pdf: FPDF, summary: str):\n",
        "    \"\"\"\n",
        "    Renders the executive summary section from structured or raw text.\n",
        "    \"\"\"\n",
        "    pdf.set_font(\"Helvetica\", \"B\", 18)\n",
        "    pdf.set_text_color(0, 102, 204)\n",
        "    pdf.cell(0, 15, \"Executive Summary\", new_x=\"LMARGIN\", new_y=\"NEXT\")\n",
        "\n",
        "    summary_data = extract_json_from_text(summary)\n",
        "\n",
        "    if summary_data and isinstance(summary_data, list):\n",
        "        for point in summary_data:\n",
        "            pdf.set_font(\"Helvetica\", \"B\", 12)\n",
        "            pdf.set_text_color(40, 40, 40)\n",
        "            pdf.multi_cell(\n",
        "                0, 8,\n",
        "                sanitize_text_for_pdf(f\"- {point.get('point', '')}\")\n",
        "            )\n",
        "\n",
        "            pdf.set_font(\"Helvetica\", \"\", 11)\n",
        "            pdf.set_text_color(80, 80, 80)\n",
        "\n",
        "            for detail in point.get(\"details\", []):\n",
        "                pdf.set_x(20)\n",
        "                pdf.multi_cell(\n",
        "                    0, 7,\n",
        "                    sanitize_text_for_pdf(f\"* {detail}\")\n",
        "                )\n",
        "            pdf.ln(2)\n",
        "    else:\n",
        "        pdf.set_font(\"Helvetica\", \"I\", 10)\n",
        "        pdf.set_text_color(80, 80, 80)\n",
        "        pdf.multi_cell(0, 7, sanitize_text_for_pdf(summary))\n",
        "\n",
        "    pdf.ln(5)\n",
        "\n",
        "# Saves the PDF to disk and returns the file path of the generated report.\n",
        "def export_pdf(pdf: FPDF, output_path: str = \"final_report.pdf\") -> str:\n",
        "    \"\"\"\n",
        "    Saves the PDF to disk and returns the output path.\n",
        "    \"\"\"\n",
        "    pdf.output(output_path)\n",
        "    return output_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rddjAU3WD0__"
      },
      "source": [
        "Utility functions for transcriber node, chapter node and summary node:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2POdsCi-Ce_k"
      },
      "outputs": [],
      "source": [
        "# Utility function for the transcriber_node to handle Whisper API logic\n",
        "def transcribe_audio_qubrid(audio_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Independent tool to send audio to Qubrid Whisper Large V3 for transcription.\n",
        "    \"\"\"\n",
        "    headers = {\"Authorization\": f\"Bearer {QUBRID_API_KEY}\"}\n",
        "    with open(audio_path, \"rb\") as f:\n",
        "        res = requests.post(\n",
        "            \"https://platform.qubrid.com/api/v1/qubridai/audio/transcribe\",\n",
        "            headers=headers,\n",
        "            files={\"file\": f},\n",
        "            data={\"model\": \"openai/whisper-large-v3\"}\n",
        "        )\n",
        "    return res.json().get(\"text\", \"Transcription failed.\")\n",
        "\n",
        "# Utility function for the chapters_node to handle LLM chapter extraction\n",
        "def generate_chapters_from_transcript(transcript: str) -> str:\n",
        "    \"\"\"\n",
        "    Independent tool to analyze transcript and generate timestamped chapters using LLM.\n",
        "    \"\"\"\n",
        "    prompt = f\"Extract chapters from transcript. Return ONLY a JSON list: [{{'time': '00:00', 'topic': 'Intro'}}]. Transcript: {transcript}\"\n",
        "    res = llm.invoke([HumanMessage(content=prompt)])\n",
        "    return res.content\n",
        "\n",
        "# Utility function for the summary_node to handle LLM content summarization\n",
        "def generate_summary_from_transcript(transcript: str) -> str:\n",
        "    \"\"\"\n",
        "    Independent tool to summarize transcript into key points using LLM.\n",
        "    \"\"\"\n",
        "    prompt = f\"Summarize transcript into key points. Return ONLY a JSON list: [{{'point': 'Title', 'details': ['Sub-bullet']}}]. Transcript: {transcript}\"\n",
        "    res = llm.invoke([HumanMessage(content=prompt)])\n",
        "    return res.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrM6TeVxATG8"
      },
      "source": [
        "## 4. Agent Orchestration (LangGraph)\n",
        "Agent workflow for transforming YouTube videos into structured insights and a downloadable PDF report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PyBPWcWsATG8"
      },
      "outputs": [],
      "source": [
        "# Shared state schema passed between agent nodes during the workflow execution\n",
        "class AgentState(TypedDict):\n",
        "    url: str\n",
        "    transcript: str\n",
        "    timestamps: str\n",
        "    summary: str\n",
        "    pdf_path: str\n",
        "\n",
        "# Agent node responsible for extracting audio and converting speech to text using Whisper\n",
        "def transcriber_node(state: AgentState):\n",
        "    print(\"\\n--- [Node: Speech-to-Text] ---\")\n",
        "    # Download and extract audio from the provided YouTube URL\n",
        "    audio_path = extract_audio_from_youtube(state['url'])\n",
        "    file_size = os.path.getsize(audio_path) / (1024 * 1024)\n",
        "    print(f\"  [+] Audio Extracted: {audio_path} ({file_size:.2f} MB)\")\n",
        "\n",
        "    print(\"  [>] Requesting Qubrid Whisper Large v3 Logic...\")\n",
        "    # Delegate API call to utility function\n",
        "    transcript = transcribe_audio_qubrid(audio_path)\n",
        "\n",
        "    print(f\"  [âœ“] Transcription Completed ({len(transcript):,} characters)\")\n",
        "    print(f\"  [!] Preview: \\\"{transcript[:150]}...\\\"\")\n",
        "    return {\"transcript\": transcript}\n",
        "\n",
        "# Agent node that analyzes the transcript and generates a timestamped chapter timeline\n",
        "def chapters_node(state: AgentState):\n",
        "    print(\"\\n--- [Node: Timeline Generation] ---\")\n",
        "    # Delegate LLM logic to utility function\n",
        "    content = generate_chapters_from_transcript(state['transcript'])\n",
        "\n",
        "    with open(\"timestamps.txt\", \"w\") as f: f.write(content)\n",
        "    # Metadata Logging\n",
        "    parsed = extract_json_from_text(content)\n",
        "    count = len(parsed) if parsed else 0\n",
        "    print(f\"  [âœ“] Analysis complete. {count} chapters detected and saved.\")\n",
        "    return {\"timestamps\": content}\n",
        "\n",
        "# Agent node that summarizes the transcript into structured key points\n",
        "def summary_node(state: AgentState):\n",
        "    print(\"\\n--- [Node: Content Summarization] ---\")\n",
        "    # Delegate LLM logic to utility function\n",
        "    content = generate_summary_from_transcript(state['transcript'])\n",
        "\n",
        "    with open(\"summary.txt\", \"w\") as f: f.write(content)\n",
        "    print(f\"  [âœ“] Summary generated ({len(content):,} characters) and saved.\")\n",
        "    return {\"summary\": content}\n",
        "\n",
        "# Agent node that synthesizes timeline and summary data into a formatted PDF report\n",
        "def synthesizer_node(state: AgentState):\n",
        "    print(\"\\n--- [Node: PDF Synthesis] ---\")\n",
        "    pdf = initialize_pdf()\n",
        "\n",
        "    print(\"  [>] Rendering timeline...\")\n",
        "    render_timeline_section(pdf, state[\"timestamps\"])\n",
        "\n",
        "    print(\"  [>] Rendering executive summary...\")\n",
        "    render_summary_section(pdf, state[\"summary\"])\n",
        "\n",
        "    output_path = export_pdf(pdf)\n",
        "\n",
        "    print(f\"  [âœ“] Report generated: {output_path}\")\n",
        "    return {\"pdf_path\": output_path}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iqQY6hVATG9"
      },
      "source": [
        "## 5. Graph Construction\n",
        "We use the `StateGraph` builder to define the fan-out/fan-in architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wms71WdIATG9"
      },
      "outputs": [],
      "source": [
        "# Initialize a LangGraph state machine with a shared agent state\n",
        "builder = StateGraph(AgentState)\n",
        "\n",
        "# Register agent nodes representing individual processing stages\n",
        "builder.add_node(\"transcribe\", transcriber_node)   # Speech-to-text conversion\n",
        "builder.add_node(\"chapters\", chapters_node)         # Chapter extraction\n",
        "builder.add_node(\"summary\", summary_node)           # Content summarization\n",
        "builder.add_node(\"synthesize\", synthesizer_node)    # Final PDF generation\n",
        "\n",
        "# Define the entry point of the graph (first node to execute)\n",
        "builder.set_entry_point(\"transcribe\")\n",
        "\n",
        "builder.add_edge(\"transcribe\", \"chapters\")\n",
        "builder.add_edge(\"transcribe\", \"summary\")\n",
        "\n",
        "builder.add_edge(\"chapters\", \"synthesize\")\n",
        "builder.add_edge(\"summary\", \"synthesize\")\n",
        "\n",
        "builder.add_edge(\"synthesize\", END)\n",
        "\n",
        "app = builder.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIZzDIw-ATG9"
      },
      "source": [
        "## 6. Execution Example\n",
        "Launch the agent with a YouTube URL. LangGraph will automatically handle the parallel scheduling of the LLM tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y53M_CxFATG9",
        "outputId": "2e403290-2216-4475-e459-6bc8c39317e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- [Node: Speech-to-Text] ---\n",
            "[Tool] Extracting audio from YouTube: https://youtu.be/osxdLudcCoE\n",
            "  [+] Audio Extracted: audio.m4a (5.87 MB)\n",
            "  [>] Requesting Qubrid Whisper Large v3 Logic...\n",
            "  [âœ“] Transcription Completed (12,799 characters)\n",
            "  [!] Preview: \"Have you ever wanted to create impressive AI-generated images from just a piece of text, but felt the setup was too daunting or technical? Think again...\"\n",
            "\n",
            "--- [Node: Timeline Generation] ---\n",
            "\n",
            "--- [Node: Content Summarization] ---\n",
            "  [âœ“] Analysis complete. 10 chapters detected and saved.\n",
            "  [âœ“] Summary generated (2,365 characters) and saved.\n",
            "\n",
            "--- [Node: PDF Synthesis] ---\n",
            "  [>] Rendering timeline...\n",
            "  [>] Rendering executive summary...\n",
            "  [âœ“] Report generated: final_report.pdf\n"
          ]
        }
      ],
      "source": [
        "inputs = {\"url\": \"https://youtu.be/osxdLudcCoE\"}\n",
        "outputs = app.invoke(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "05a388b5",
        "outputId": "f4c4f371-6e37-48d1-c15c-a44b668c58d1"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_a04c5370-3a75-4b1d-8307-1dfddc633319\", \"final_report.pdf\", 3299)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Download the generated PDF\n",
        "from google.colab import files\n",
        "files.download(outputs['pdf_path'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTPg4s-GSx4a"
      },
      "source": [
        "## Workflow Visualization\n",
        "\n",
        "The graph shows how data flows through transcription, parallel content analysis, and final report synthesis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "L26KgCimSte7",
        "outputId": "9cdb27ce-0b85-4be7-c445-b833a63765cf"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import Image\n",
        "Image(app.get_graph().draw_mermaid_png())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8bLPt0yXfmA"
      },
      "source": [
        "We've built a parallel agent workflow system that goes beyond simple linear chains by:\n",
        "\n",
        "- Task Parallelism: Running nodes concurrently to save time.\n",
        "- State Persistence: Maintaining structured data flow across all modular nodes.\n",
        "- Efficient Orchestration: Separating heavy I/O tasks from core AI reasoning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cogLosfwXlXP"
      },
      "source": [
        "## Start Building Intelligent Agents âš¡\n",
        "\n",
        "[ðŸ”‘ Get Your API Key](https://platform.qubrid.com/signup) Â·\n",
        "[ðŸ¤– Explore Available Models](https://docs.platform.qubrid.com/inferencing/Serverless%20Models) Â·\n",
        "[ðŸ Try the Playground](https://platform.qubrid.com/playground)\n",
        "\n",
        "__Build, deploy, and scale agentic workflows with Qubrid AI.__"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "LangGraph",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
